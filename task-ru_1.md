[[_TOC_]]

# Look-a-Like сервис

## Бизнес-контекст

Вы работаете в банке. Банк обрабатывает обезличенные данные о транзакциях клиентов в торгово-сервисных предприятиях.

Партнёры запускают **офферы** (рекламные акции с кэшбэком) для привлечения новых клиентов. Показы стоят денег, поэтому ключевая задача — показать **конкретный оффер** тем, кто с наибольшей вероятностью **откликнется на него**.

### Проблема

У каждого партнёра уже есть клиентская база — клиенты, которые совершали транзакции. Каждый оффер имеет свои характеристики: тип, минимальный чек, текст, период действия. Партнёру важно:

- **Не показывать** оффер текущим клиентам (они уже знают бренд)
- **Показать** оффер новым клиентам, которые с высокой вероятностью **откликнутся именно на этот оффер**

Нужно найти **look-a-like аудиторию под конкретный оффер** — клиентов банка, которые:
- Похожи по поведению на тех, кто откликался на подобные офферы
- Ранее не совершали транзакции у данного партнёра

### Сценарий дрейфа: новый оффер

Модель обучена на исторических данных: какие клиенты реагируют на какие офферы. Но мир не стоит на месте:

1. Партнёр запускает **новый оффер** — возможно, на другую аудиторию, с другим чеком, в другой период
2. Появляются **новые транзакции** — поведение клиентов меняется
3. Приходят **новые клиенты**, которых модель раньше не видела

Ваша задача — **автоматически обнаружить**, что данные изменились, **самостоятельно решить** нужно ли дообучение, и если да — **дообучить** модель.

---

## Что нужно сделать

1. Построить **ML-модель** look-a-like аудитории под конкретный оффер
2. Обернуть в **Docker + REST API**
3. Реализовать **приём данных** через API потоковой загрузки батчей
4. Реализовать **валидацию данных** — **Great Expectations**
5. Настроить **версионирование** данных и моделей — **DVC**
6. Реализовать **мониторинг дрейфа** данных — **Evidently**
7. Вести **трекинг экспериментов** — **MLflow**
8. Реализовать **автоматический пайплайн**: при получении новых данных сервис сам валидирует, проверяет дрейф и принимает решение о дообучении

Данные поступают через REST API. Сервис должен сохранять полученные данные в **S3 (MinIO)** и версионировать их в DVC. Пайплайн должен быть **воспроизводимым**: `dvc repro` должен работать.

Архитектуру и техническую реализацию вы определяете самостоятельно: Dockerfile, docker-compose, S3 (MinIO) для данных/моделей/чекпоинтов/артефактов и другие необходимые компоненты.

---

## Входные данные

### Данные для разработки

Для разработки предоставляются два архива с версиями данных:

- `v1.zip`
- `v2.zip`

Внутри каждого архива лежит соответствующая папка версии (`v1/` или `v2/`) с CSV-таблицами:

- `prod_clients.csv`
- `prod_financial_transaction.csv`
- `financial_account.csv`
- `offer_activation.csv`
- `offer_reward.csv`
- `offer_seens.csv`
- `prizm_segments.csv`
- `t_merchant.csv`
- `t_offer.csv`

Используйте v1 и v2, чтобы:
1. Изучить структуру данных и связи между таблицами
2. Построить фичи и обучить модель на v1
3. Сравнить распределения v1 и v2 — увидеть, где наблюдается дрейф
4. Настроить Evidently и подобрать пороги drift_score
5. Проверить, что ваш пайплайн корректно переобучается при дрейфе

> **Важно:** локальные `v1/v2` нужны только для разработки. При проверке чекер отправляет **другие версии данных** того же формата. Не привязывайтесь к конкретным значениям и распределениям.

Дополнительно доступны архивы `receipts_v1.zip` и `receipts_v2.zip` (в корне репозитория, аналогично `v1.zip`/`v2.zip`) с таблицей `receipts` (`user_id`, `date_operated`, `category_name`, `items_count`, `items_cost`) для feature engineering; этот источник **входит** в API-контракт `/data/batch` как отдельная таблица `receipts`.

### Доставка данных

При проверке данные поступают в сервис **через REST API** в формате JSON. Чекер отправляет записи **батчами** (`POST /data/batch`) — по одной или нескольким таблицам за раз. После загрузки всех данных версии чекер отправляет **commit** (`POST /data/commit`), который запускает обработку.

Для `POST /data/batch` используйте логические имена таблиц:

- `people`
- `segments`
- `transaction`
- `offer`
- `merchant`
- `financial_account`
- `offer_seens`
- `offer_activation`
- `offer_reward`
- `receipts`

### Связи между таблицами

Основные связи в текущем датасете:

- `people` (`prod_clients.csv`) связан с `segments`, `financial_account`, `transaction` по `user_id`.
- `offer` (`t_offer.csv`) связан с `merchant` (`t_merchant.csv`) по `merchant_id_offer`.
- `transaction` содержит `brand_dk`, а `merchant` содержит `brand_dk` и `merchant_id_offer`.
- Для связи транзакций с офферами используйте цепочку: `transaction.brand_dk -> merchant.brand_dk -> merchant.merchant_id_offer -> offer.merchant_id_offer`.
- Таблицы `offer_seens`, `offer_activation`, `offer_reward` связывают пользователя и оффер по паре (`user_id`, `offer_id`).
- `receipts` связан с `people` по `user_id` и даёт дополнительный поведенческий слой для фичей.

---

### Логические таблицы и файлы

| Логическая таблица (API) | Файл в `template/data` | Ключевые поля |
|---------|----------|----------|
| `people` | `prod_clients.csv` | `user_id`, `age_bucket`, `gender_cd`, `region`, `last_activity_day` |
| `segments` | `prizm_segments.csv` | `user_id`, `segment`, `region_size`, `auto`, `traveler`, `entrepreneur`, `vip_status` |
| `transaction` | `prod_financial_transaction.csv` | `transaction_id`, `user_id`, `merchant_id_tx`, `event_date`, `amount_bucket`, `online_transaction_flg`, `brand_dk` |
| `offer` | `t_offer.csv` | `offer_id`, `merchant_id_offer`, `start_date`, `end_date`, `offer_text` |
| `merchant` | `t_merchant.csv` | `merchant_id_offer`, `merchant_status`, `brand_dk` |
| `financial_account` | `financial_account.csv` | `user_id`, `product_cd`, `open_month`, `close_month`, `account_status_cd` |
| `offer_seens` | `offer_seens.csv` | `user_id`, `offer_id`, `start_date`, `end_date` |
| `offer_activation` | `offer_activation.csv` | `user_id`, `offer_id`, `activation_date` |
| `offer_reward` | `offer_reward.csv` | `user_id`, `offer_id`, `event_date`, `reward_amt` |
| `receipts` | `receipts.csv` | `user_id`, `date_operated`, `category_name`, `items_count`, `items_cost` |

### Справочник сегментов

Ниже приведено соответствие кодов `segment` и их наименований.

#### Москва (`m_*`)

| Код | Название |
|-----|----------|
| `m_01` | Устойчивое благополучие |
| `m_02` | Активный ритм жизни |
| `m_03` | Молодые и перспективные |
| `m_04` | Семейно-ориентированные жители Москвы |
| `m_05` | Люди предпенсионного возраста |
| `m_06` | Специалисты, переехавшие в столицу |
| `m_07` | Ценящие баланс работы и отдыха |
| `m_08` | Специалисты прикладных профессий |
| `m_09` | Старшее поколение столицы |
| `m_10` | Специалисты базовой квалификации |
| `m_11` | Молодёжь Москвы |

#### Крупные города (`u_*`)

| Код | Название |
|-----|----------|
| `u_01` | Высокодоходные жители крупных городов |
| `u_02` | Молодые обеспеченные жители крупных городов |
| `u_03` | Состоятельные жители городов-миллионников |
| `u_04` | Финансово устойчивые горожане |
| `u_05` | В поиске карьерной и жизненной траектории |
| `u_06` | Семейно-ориентированные жители крупных городов |
| `u_07` | Адаптирующиеся жители крупных городов |
| `u_08` | Зрелые жители, ориентированные на личный комфорт |
| `u_09` | Молодёжь крупных городов |
| `u_10` | Жители миллионников с ограниченными доходами |
| `u_11` | Взрослые жители миллионников со стабильным укладом |
| `u_12` | В начале самостоятельного пути |

#### Города (`t_*`)

| Код | Название |
|-----|----------|
| `t_01` | Финансово устойчивые жители города |
| `t_02` | Молодые перспективные жители города |
| `t_03` | Состоятельные жители города |
| `t_04` | Семейно-ориентированные жители города |
| `t_05` | Специалисты прикладных и производственных сфер |
| `t_06` | Жители, ориентированные на стабильный образ жизни |
| `t_07` | Жители, адаптирующиеся к городскому ритму |
| `t_08` | Старшее поколение города |
| `t_09` | Молодёжь города |
| `t_10` | Жители города с ограниченными доходами |
| `t_11` | Взрослые жители города со стабильным укладом |
| `t_12` | Начинающие самостоятельный путь в городе |

#### Сельская местность (`r_*`)

| Код | Название |
|-----|----------|
| `r_01` | Финансово устойчивые жители села |
| `r_02` | Молодые перспективные жители села |
| `r_03` | Экономически успешные жители села |
| `r_04` | Работники прикладных и производственных сфер |
| `r_05` | Старшее поколение села |
| `r_06` | Взрослые жители села со стабильным укладом |
| `r_07` | Семейно-ориентированные жители села |
| `r_08` | Молодёжь села |
| `r_09` | Занятые профессиональным развитием |
| `r_10` | В начале самостоятельного пути в селе |

---

## Как работает проверка

Чекер последовательно отправляет **несколько версий данных** через `POST /data/batch` + `POST /data/commit`. Ваш сервис должен **сам** решить: есть ли дрейф и нужно ли переобучение.

Некоторые версии содержат **реальный дрейф**, а некоторые — **нет**. Одна из версий может содержать **некорректные данные** (пропущенные батчи, отсутствующие таблицы, некорректные записи). Порядок и количество версий заранее неизвестны.

```
Чекер                                        Ваш сервис
──────                                       ──────────

    ═══ ФАЗА 1: первичное обучение ═══

1. POST /data/batch (people, v1)              Принимает, буферизирует
   POST /data/batch (transaction, v1, 1/3)
   POST /data/batch (offer, v1)
   POST /data/batch (merchant, v1)
   POST /data/batch (transaction, v1, 2/3)   Батчи приходят
   POST /data/batch (segments, v1)            в произвольном порядке
   POST /data/batch (offer_seens, v1)
   POST /data/batch (offer_activation, v1)
   POST /data/batch (offer_reward, v1)
   POST /data/batch (receipts, v1)
   POST /data/batch (transaction, v1, 3/3)
   POST /data/batch (financial_account, v1)

2. POST /data/commit {"version":"v1"}    →   Все данные v1 получены.
                                             Валидация (GE) → фичи → обучение
3. Опрашивает GET /status               ←   ready: true, model_version: "1.0"

4. POST /lookalike (набор офферов)         ←   Предсказания на базовой модели
   → Замеряет MAP@100 (baseline)

    ═══ ФАЗА 2+: серия обновлений ═══

   Для КАЖДОЙ версии vN:

5. POST /data/batch (таблицы vN)        →   Принимает батчи
6. POST /data/commit {"version":"vN"}   →   Обрабатывает:
                                             валидация (GE) → обновление данных/фичей
                                             → Evidently → решение
                                             — невалидные данные? → пропускает
                                             — дрейф? → переобучает модель
                                             — нет дрейфа? → данные обновлены,
                                               модель прежняя
7. Опрашивает GET /status               ←   pipeline_status: "idle"

8. GET /monitoring/data-quality         ←   valid: true/false
9. GET /monitoring/drift                ←   drift_detected: true/false
10. GET /model/info                     ←   model_version — сменилась?

11. POST /lookalike (ТЕ ЖЕ офферы)        ←   MAP@100 (vN)
    → Сравнивает с предыдущим                Δ = прирост / стабильность
```

Ключевой момент: чекер **не указывает** сервису, когда переобучать модель. Он лишь отправляет данные и сигнал `commit`. После каждого `commit` сервис **всегда** обновляет каталог данных (новые офферы, транзакции, фичи). Решение о **переобучении модели** принимается отдельно — только при обнаружении статистического дрейфа. Если сервис переобучает модель, когда дрейфа нет, или не переобучает, когда дрейф есть, — баллы снижаются.

> **Важно:** появление новых офферов или мерчантов в данных — это **НЕ** дрейф. Дрейф — это **статистическое изменение распределений** признаков (сдвиг сумм транзакций, изменение частоты покупок, смена сегментов клиентов и т.д.). Некоторые версии могут содержать новые сущности, но стабильные распределения — переобучаться в этом случае **не нужно**.

> **Как считается MAP@100:** чекер располагает данными о **реальных будущих транзакциях**. Для каждого оффера ground truth — **новые клиенты**, которые фактически совершили транзакцию у мерчанта **в период действия оффера**, но **не совершали транзакций у этого мерчанта ранее** (до `start_date`). Ground truth согласован с правилом фильтрации: и вы, и чекер исключаете старых клиентов. Для текущего датасета связь транзакции и мерчанта оффера строится через `brand_dk` и `merchant_id_offer`. Характеристики оффера (период, чек, текст) **влияют** на то, кто окажется в ground truth.

> **Таймаут:** после каждого `POST /data/commit` чекер ждёт не более **10 минут** до `pipeline_status: "idle"`. Если за это время пайплайн не завершился — все баллы за данную версию обнуляются, и чекер переходит к следующей.

> **Fail-soft (production):** ошибка отдельного батча, версии данных или этапа пайплайна не должна останавливать сервис целиком. `/lookalike` должен продолжать обслуживаться на последней успешно деплоенной модели. При невалидной версии данных — обучение пропускается, сервис остаётся доступным.

---

## Что вы сдаёте

Репозиторий с вашим решением. Обязательно должно присутствовать:

- `Dockerfile` — Docker-образ вашего сервиса
- `docker-compose.yml` — оркестрация вашего сервиса и необходимой инфраструктуры (MinIO, MLflow и т.д.)
- `dvc.yaml` — DVC-пайплайн
- `params.yaml` — параметры пайплайна
- `reports/` — генерируемые отчёты (результат `dvc repro`)

Структуру, названия файлов и разбиение по модулям вы определяете сами.

> **Важно:** Мы предоставляем только данные и `openapi.yml`. Весь остальной код, Dockerfile, docker-compose и инфраструктура — **ваши**.

### Запуск

Чекер запускает в корне репозитория:

```bash
docker compose up -d
```

После этого ожидает `GET http://localhost:80/ready` → 200 в течение **180 секунд**. Все ваши сервисы (MinIO, MLflow и т.д.) должны подняться и быть готовы к работе за это время. Сервисы общаются между собой через **docker-сеть** (локально).

Если `/ready` не ответил 200 — **0 баллов за всё решение**.

---

## API-контракт

> Полное описание: [`openapi.yml`](openapi.yml)

Сервис **обязан** слушать на порту **80**.

### `GET /ready`

```json
{"status": "ok"}
```

### `POST /data/batch`

Загрузка батча записей для одной таблицы. Может вызываться **многократно** — батчи могут приходить в произвольном порядке между таблицами. Большие таблицы разбиваются на несколько батчей.

**Запрос:**
```json
{
  "version": "v2",
  "table": "transaction",
  "batch_id": 1,
  "total_batches": 3,
  "records": [
    {"transaction_id": 1, "user_id": 42, "merchant_id_tx": 75, "event_date": "2025-06-01", "amount_bucket": "10k+", "online_transaction_flg": "N", "brand_dk": 18601},
    {"transaction_id": 2, "user_id": 15, "merchant_id_tx": 110, "event_date": "2025-06-02", "amount_bucket": "1k+", "online_transaction_flg": "Y", "brand_dk": 29256}
  ]
}
```

**Ответ (200 OK):**
```json
{"status": "accepted", "table": "transaction", "batch_id": 1}
```

> **Идемпотентность:** повторный вызов с тем же `version` + `table` + `batch_id` **не должен** дублировать записи.
>
> Обязательные поля запроса: `version`, `table`, `batch_id`, `total_batches`, `records`.
> Допустимые значения `table`: `people`, `segments`, `transaction`, `offer`, `merchant`, `financial_account`, `offer_seens`, `offer_activation`, `offer_reward`, `receipts`.
> Неизвестное имя таблицы или отсутствие обязательного поля — `400`.
> Пустой `records` — допустимый no-op (без падения сервиса).

### `POST /data/commit`

Сигнал: все данные для указанной версии загружены. Сервис запускает обработку **асинхронно** (в фоне).

**Запрос:**
```json
{"version": "v2"}
```

**Ответ (200 OK):**
```json
{"status": "accepted", "tables_received": ["people", "segments", "transaction", "offer", "merchant", "financial_account", "offer_seens", "offer_activation", "offer_reward", "receipts"]}
```

> **Идемпотентность:** повторный commit с тем же `version` **не должен** запускать пайплайн повторно.
>
> Первый успешный `commit` фиксирует (закрывает) версию данных.
> `commit` до отправки батчей должен обрабатываться корректно (без `500`): версия считается невалидной, обучение пропускается (`action_taken: "skipped"`).

### `GET /status`

Текущее состояние сервиса и пайплайна.

```json
{
  "ready": true,
  "model_version": "2.0",
  "data_version": "v2",
  "pipeline_status": "idle"
}
```

- `ready` — сервис готов отвечать на `/lookalike` (даже если пайплайн работает в фоне — старая модель продолжает обслуживать запросы)
- `data_version` — последняя успешно обработанная версия данных в каталоге (может быть новее, чем `trained_on` у текущей модели)
- `pipeline_status` — `"idle"` | `"running"` | `"failed"` (после успешной обработки сервис возвращается в `"idle"`)

### `POST /lookalike`

**Запрос:**
```json
{
  "merchant_id": 75,
  "offer_id": 42,
  "top_n": 100
}
```

**Ответ (200 OK):**
```json
{
  "merchant_id": 75,
  "offer_id": 42,
  "audience": [
    {"user_id": 28, "score": 0.95},
    {"user_id": 43, "score": 0.91}
  ],
  "audience_size": 100,
  "model_version": "1.0",
  "reasons": [
    {"feature": "segment=u_02", "impact": 0.34},
    {"feature": "tx_count_30d", "impact": 0.21},
    {"feature": "online_share_90d", "impact": -0.08}
  ]
}
```

- `audience` — отсортирован по `score` по убыванию
- `score` — оценка (0..1)
- `reasons` — топ факторов/фичей, повлиявших на ранжирование для этого ответа; каждый элемент содержит `feature` и численный `impact` (может быть отрицательным)
- `reasons` должны проходить sanity-check: при контролируемой подмене одной ключевой фичи пользователя (`segment`, доля онлайн-трат и т.п.) топ-причина и/или `score` должны меняться предсказуемо; знак `impact` — логичный
- **Не включать** текущих клиентов мерчанта (совершавших транзакции до периода оффера)
- Разные офферы одного мерчанта могут давать **разную** аудиторию
- `top_n` — целое число в диапазоне `1..1000`; вне диапазона — `400`

**Коды:** `200`, `400`, `404`, `503`

### `POST /lookalike/batch`

**Запрос:**
```json
{
  "requests": [
    {"merchant_id": 75, "offer_id": 42, "top_n": 50},
    {"merchant_id": 110, "offer_id": 99, "top_n": 100}
  ]
}
```

**Ответ (200 OK):**
```json
{
  "results": [
    {
      "merchant_id": 75,
      "offer_id": 42,
      "audience": [...],
      "audience_size": 50,
      "model_version": "1.0",
      "reasons": [...]
    }
  ]
}
```

Каждый элемент `results` должен соответствовать контракту `/lookalike`, включая поле `reasons`.

### `GET /model/info`

Метаданные модели, включая **lineage** — на каких данных обучена.

```json
{
  "model_name": "lookalike-cf",
  "model_version": "2.0",
  "trained_on": "v2",
  "features_count": 47,
  "train_metrics": {
    "precision_at_100": 0.42
  }
}
```

Состав полей ответа расширяемый, но `model_name`, `model_version`, `trained_on` — **обязательные**.

### `GET /monitoring/drift`

```json
{
  "drift_detected": true,
  "drift_score": 0.73,
  "action_taken": "retrained"
}
```

- `drift_detected` — индикатор наличия дрейфа
- `drift_score` — числовая оценка дрейфа
- `action_taken` — какое действие предпринял сервис (`"retrained"` | `"none"` | `"skipped"`)

Дополнительные поля в этом ответе — на усмотрение реализации, но `drift_detected`, `drift_score`, `action_taken` — **обязательные**.

### `GET /monitoring/data-quality`

Результат валидации последней версии данных (Great Expectations).

```json
{
  "version": "v2",
  "valid": true,
  "checks_total": 12,
  "checks_passed": 11,
  "checks_failed": 1,
  "failed_checks": [
    {
      "table": "transaction",
      "check": "user_id_not_null",
      "details": "3 rows with null user_id"
    }
  ]
}
```

- `valid` (bool) — данные прошли валидацию (все критичные проверки пройдены)
- `checks_total` / `checks_passed` / `checks_failed` — статистика проверок
- `failed_checks` — список непройденных проверок

Валидация должна быть **содержательной** — минимум **5 проверок** (`checks_total ≥ 5`), покрывающих разные аспекты качества данных. Одной-двух формальных проверок ("таблица не пустая") **недостаточно**.

Примеры осмысленных проверок: отсутствие `NaN` в ключевых полях (`user_id`, `merchant_id_tx`, `offer_id`), допустимые значения категориальных колонок, корректность дат, ссылочная целостность между таблицами, минимальное количество записей, уникальность ID.

> **Внимание:** одна из версий чекера содержит **специально подготовленные ошибки** в данных. Формальная валидация может их **не выявить**. Если ваш сервис обучится на некорректных данных — качество модели упадёт, и баллы за соответствующие проверки будут потеряны.

> **Важно:** чекер проверяет, что сервис действительно нашёл проблему: в `failed_checks` должны быть релевантные причины, а не только общий флаг ошибки. Простого ответа `valid: false` без содержательной диагностики недостаточно.

> Если данные не прошли валидацию (`valid: false`), сервис не должен обучать модель на них. В этом случае `action_taken` в `/monitoring/drift` должен быть `"skipped"`.

### `GET /experiments`

История экспериментов из MLflow. Каждое обучение/переобучение модели должно логироваться как эксперимент.

```json
{
  "experiments": [
    {
      "run_id": "a1b2c3",
      "data_version": "v1",
      "model_version": "1.0",
      "metrics": {
        "precision_at_100": 0.31,
        "map_at_100": 0.29
      },
      "params": {
        "model_type": "als",
        "n_factors": 64
      },
      "timestamp": "2026-01-15T10:30:00"
    },
    {
      "run_id": "d4e5f6",
      "data_version": "v2",
      "model_version": "2.0",
      "metrics": {
        "precision_at_100": 0.44,
        "map_at_100": 0.41
      },
      "params": {
        "model_type": "als",
        "n_factors": 64
      },
      "timestamp": "2026-01-15T11:15:00"
    }
  ]
}
```

Обязательные поля каждого эксперимента: `run_id`, `data_version`, `model_version`, `metrics`, `timestamp`. Поле `params` — опционально. Список должен содержать **все** запуски обучения за текущую сессию.

---

## Ограничения

| Параметр | Лимит |
|----------|-------|
| Время старта | < 180 секунд до готовности `/ready` (иначе 0 за всё) |
| Время обработки после `/data/commit` | < 10 минут до `pipeline_status: "idle"` |
| Память | < 8 GB |
| CPU | 4 ядра |
| GPU | Нет |
| Время ответа `/lookalike` | < 2 секунды (p95) |
| Размер Docker-образа | < 4 GB |
| Сеть | **Нет доступа в интернет** при запуске и проверке |
| Общее время работы сервиса в рамках одной сессии проверки | ≤ 60 минут (после этого проверка может быть прервана) |

---

## Оценка — 100 баллов

Оценка состоит из **100 бинарных проверок** (0 или 1 балл каждая), сгруппированных в **5 блоков**.

> **Глобальное правило — запуск:** если `GET /ready` не возвращает 200 в течение **180 секунд** после старта — **0 баллов за всё**. Проверять нечего, если сервис не запустился.

> **Глобальное правило — качество:** если MAP@100 на базовой модели (после первого обучения) **хуже случайного ранжирования** — **0 баллов за всё**. Нет смысла проверять MLOps, если ML не работает.

> **Антифрод:** любая попытка обмануть систему проверки приводит к **обнулению всего результата**. Это включает, но не ограничивается:
> - Жёстко закодированные ответы или заранее подготовленная модель, не использующая входные данные
> - Одинаковая аудитория для всех офферов
> - `score` одинаков у всех пользователей (нет ранжирования)
> - `model_version` меняется без фактического переобучения (метрики и предсказания не изменились)
> - Фейковые эксперименты в MLflow (одинаковые `run_id`, невалидные timestamps)
> - Использование чужого кода без понимания его работы

> **Собеседование:** после автоматической проверки проводится **собеседование**. Вы должны объяснить своё решение: архитектуру, выбор модели, логику детекции дрейфа, устройство пайплайна. Собеседование может **изменить результат в обе стороны**:
> - Если участник **не может объяснить** свой код — баллы **снимаются** (вплоть до полного обнуления)
> - Если часть функциональности реализована формально или не работает — баллы за соответствующие блоки **снимаются**
> - Если чекер не засчитал баллы из-за технической ошибки, но участник **демонстрирует и объясняет** работающее решение — баллы могут быть **восстановлены**

---

### Блок 1: Пайплайн — 20 проверок

| # | Проверка |
|---|----------|
| 1.1 | `GET /ready` → 200, ответ соответствует контракту |
| 1.2 | `POST /data/batch` → 200, ответ соответствует контракту |
| 1.3 | Батчи разных таблиц принимаются в произвольном порядке |
| 1.4 | Идемпотентность: повторный батч не дублирует записи |
| 1.5 | `POST /data/commit` → 200, `tables_received` корректен |
| 1.6 | Идемпотентность: повторный commit не перезапускает пайплайн |
| 1.7 | Пайплайн завершается в пределах таймаута |
| 1.8 | `GET /status` → 200, обязательные поля |
| 1.9 | `pipeline_status` корректно отражает состояние (`running` → `idle`) |
| 1.10 | `ready: true` после завершения пайплайна |
| 1.11 | `tables_received` соответствует фактически отправленным таблицам |
| 1.12 | Батч с неизвестным именем таблицы → 400, не 500 |
| 1.13 | `commit` до отправки батчей → корректная обработка, не 500 |
| 1.14 | `GET /model/info` → 200, обязательные поля |
| 1.15 | `GET /monitoring/drift` → 200, обязательные поля |
| 1.16 | `GET /monitoring/data-quality` → 200, обязательные поля |
| 1.17 | `GET /experiments` → 200, ≥1 эксперимент с обязательными полями |
| 1.18 | `/data/batch` с пустым массивом `records` → корректная обработка, не 500 |
| 1.19 | `/data/batch` без обязательного поля → 400, не 500 |
| 1.20 | DVC-конфигурация присутствует и валидна: `dvc.yaml` + `params.yaml`, стадии пайплайна описаны корректно |

---

### Блок 2: Качество модели — 15 проверок

| # | Проверка |
|---|----------|
| 2.1 | `POST /lookalike` → 200 для известного оффера |
| 2.2 | Ответ соответствует контракту (обязательные поля, типы, формат, включая `reasons`) |
| 2.3 | Фильтрация: текущие клиенты мерчанта не включены в аудиторию |
| 2.4 | `audience_size` ≤ `top_n` |
| 2.5 | Контрфактуальный sanity-check `reasons`: при 2–3 контролируемых подменах одной фичи меняются `score` и/или топ-причина, затронутая фича становится топ-причиной с логичным знаком `impact`; для заметно разных офферов причины тоже заметно различаются |
| 2.6 | MAP@100 > 15% |
| 2.7 | MAP@100 > 20% |
| 2.8 | MAP@100 > 25% |
| 2.9 | MAP@100 > 30% |
| 2.10 | MAP@100 > 35% |
| 2.11 | MAP@100 > 40% |
| 2.12 | MAP@100 > 45% |
| 2.13 | MAP@100 > 50% |
| 2.14 | MAP@100 > 55% |
| 2.15 | MAP@100 > 60% |

Каждый следующий уровень MAP — сложнее предыдущего. Чекер использует закрытый набор офферов. Напоминаем: если MAP@100 ниже случайного ранжирования — **0 баллов за всё решение**.

---

### Блок 3: Надёжность — 15 проверок

| # | Проверка |
|---|----------|
| 3.1 | `POST /lookalike/batch` → 200, количество результатов верно |
| 3.2 | Результаты батч-режима согласуются с одиночными запросами |
| 3.3 | Несуществующий `merchant_id` или `offer_id` → 404 |
| 3.4 | Невалидный запрос `/lookalike` → 400 |
| 3.5 | Граничные значения `top_n` → корректная обработка |
| 3.6 | Детерминизм: повторный запрос → идентичный ответ и порядок |
| 3.7 | 10–50 конкурентных запросов к `/lookalike` и `POST /data/batch` → все без ошибок |
| 3.8 | При конкурентной записи батчей и инференсе нет гонок состояния: данные не повреждаются, ответы консистентны |
| 3.9 | Время ответа `/lookalike` < 2с (p95) |
| 3.10 | `/lookalike` → 200 во время работы пайплайна (без остановки сервиса) |
| 3.11 | Ответ валиден во время пайплайна — старая модель продолжает работать |
| 3.12 | `pipeline_status: "running"` корректно отображается во время обработки |
| 3.13 | Новый оффер до обработки новой версии данных → 404 |
| 3.14 | Новый оффер после обработки (даже без переобучения модели) → валидный ответ |
| 3.15 | При падении очередного запуска пайплайна `/lookalike` продолжает отвечать `200` на предыдущей модели (fail-soft, без `500`) |

Сервис **не должен** возвращать 500 ни при каких обстоятельствах.

---

### Блок 4: Обнаружение дрейфа — 20 проверок

| # | Проверка |
|---|----------|
| 4.1 | `drift_detected: true` на версии с дрейфом |
| 4.2 | `action_taken: "retrained"` |
| 4.3 | `model_version` изменилась после переобучения |
| 4.4 | `data_version` в `/status` обновилась |
| 4.5 | MAP@100 не упал после переобучения |
| 4.6 | MAP@100 вырос после переобучения |
| 4.7 | Новый эксперимент появился в `/experiments` |
| 4.8 | `drift_detected: false` на версии без дрейфа |
| 4.9 | `action_taken: "none"` |
| 4.10 | `model_version` не изменилась без дрейфа |
| 4.11 | MAP@100 стабилен без дрейфа |
| 4.12 | Количество экспериментов не выросло без дрейфа |
| 4.13 | `valid: true` на корректных данных, `checks_total` ≥ 5 |
| 4.14 | `trained_on` соответствует данным обучения |
| 4.15 | `model_version` в `/model/info` совпадает с `/status` |
| 4.16 | `drift_score` адекватен при дрейфе |
| 4.17 | `drift_score` адекватен без дрейфа |
| 4.18 | Метрики в `/experiments` совпадают с `train_metrics` в `/model/info` |
| 4.19 | Обработка серии: дрейф → нет дрейфа |
| 4.20 | Обработка серии: нет дрейфа → дрейф |

Достаточно одного корректного цикла: обнаружил дрейф → переобучился → качество выросло. Среди тестовых версий будут данные с **новыми офферами, но без статистического дрейфа** — переобучаться на них не нужно.

---

### Блок 5: Продакшен — 30 проверок

| # | Проверка |
|---|----------|
| 5.1 | `valid: false` на некорректных данных |
| 5.2 | `action_taken: "skipped"` при `valid: false` |
| 5.3 | `model_version` не изменилась после некорректных данных |
| 5.4 | MAP@100 стабилен после некорректных данных |
| 5.5 | Сервис не упал после некорректных данных (`/ready` → 200) |
| 5.6 | Количество экспериментов не выросло после пропуска обучения |
| 5.7 | Полная серия: чередование дрейфа и нормы |
| 5.8 | Полная серия: несколько версий без дрейфа подряд |
| 5.9 | Полная серия: некорректные данные между нормальными |
| 5.10 | `action_taken` корректен на всей серии |
| 5.11 | `drift_score` адекватен на всей серии |
| 5.12 | `data_version` актуальна после каждого обновления |
| 5.13 | `trained_on` корректен после серии |
| 5.14 | `model_version` корректна после серии |
| 5.15 | `/monitoring/drift` обновляется после каждой версии |
| 5.16 | `/monitoring/data-quality` обновляется после каждой версии |
| 5.17 | Количество экспериментов = числу фактических переобучений |
| 5.18 | `/experiments`: хронология корректна (timestamps возрастают) |
| 5.19 | `/experiments`: метрики реально различаются между экспериментами |
| 5.20 | Нет регрессии MAP на протяжении серии |
| 5.21 | MAP@100 после серии ≥ baseline |
| 5.22 | Аудитория изменилась после переобучения на данных с дрейфом |
| 5.23 | Аудитория для существующих офферов стабильна на версии без дрейфа |
| 5.24 | Значение `score` изменилось после переобучения |
| 5.25 | `data_version`, `trained_on`, DVC-lineage (`dvc.lock`) и `/experiments` — согласованы между собой |
| 5.26 | Новый оффер после обработки версии → валидный ответ |
| 5.27 | Сервис стабилен после 3+ циклов обновлений |
| 5.28 | `/data/batch` принимается после завершения серии (готов к новым данным) |
| 5.29 | `dvc repro` успешно выполняется в окружении проверки без ручных шагов |
| 5.30 | `/status` → `ready: true` в конце всех проверок |

Ваш сервис должен работать как продакшен-система: не падать, не терять состояние, корректно обрабатывать любые входные данные.

---


## FAQ

**Какой язык программирования?** <br/>
Рекомендуется использовать Python.

**Можно ли использовать любую ML-модель?** <br/>
Да, но она должна быть **локальной**. При запуске и проверке доступа в интернет нет.

**Можно ли использовать GPU?** <br/>
Нет. Только CPU.

**Какая версия решения будет проверяться?** <br/>
На проверку будет отправлен последний коммит в ветке `main` на момент дедлайна.
